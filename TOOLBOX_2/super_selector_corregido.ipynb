{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUPERSELECTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, SelectFromModel, RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def super_selector(dataset, target_col=\"\", selectores={}, hard_voting=[]):\n",
    "    \"\"\"\n",
    "    Selecciona características de un dataframe de features según diferentes métodos de selección.\n",
    "\n",
    "    Args:\n",
    "        dataset (pandas.DataFrame): El dataframe de características.\n",
    "        target_col (str): El nombre de la columna objetivo.\n",
    "        selectores (dict): Un diccionario con métodos de selección como claves y sus parámetros como valores.\n",
    "        hard_voting (list): Una lista de características para realizar hard voting.\n",
    "\n",
    "    Returns:\n",
    "        dict: Un diccionario que contiene las características seleccionadas por cada método de selección\n",
    "              y el resultado del hard voting si se especifica.\n",
    "\n",
    "    Ejemplo:\n",
    "        selectores = {\n",
    "            \"KBest\": 5,\n",
    "            \"FromModel\": [RandomForestClassifier(), 5],\n",
    "            \"RFE\": [LogisticRegression(), 5, 1]\n",
    "        }\n",
    "        result = super_selector(train_set_titanic, target_col=\"Survived\", selectores=selectores, hard_voting=[\"Pclass\", \"who\", \"embarked_S\", \"fare\", \"age\"])\n",
    "        print(result)\n",
    "    \"\"\"\n",
    "\n",
    "    result = {}  # Se inicializa un diccionario para almacenar el resultado de la selección de características.\n",
    "\n",
    "    # Verificar si target_col es válido\n",
    "    if target_col and target_col in dataset.columns:  # Verifica si se proporcionó un nombre de columna objetivo y si existe en el dataframe.\n",
    "        target = dataset[target_col]  # Guarda la columna objetivo en 'target'.\n",
    "        features = dataset.drop(columns=[target_col])  # Elimina la columna objetivo del dataframe de características y guarda el resto en 'features'.\n",
    "    else:\n",
    "        target = None  # Si no se proporciona una columna objetivo válida, se establece como 'None'.\n",
    "        features = dataset.copy()  # Si no se proporciona una columna objetivo válida, se copian todas las características del dataframe.\n",
    "\n",
    "    # Seleccionar características basadas en selectores\n",
    "    for selector, params in selectores.items():  # Itera sobre cada método de selección y sus parámetros.\n",
    "        if selector == \"KBest\":  # Si el método de selección es 'KBest' (Selección de las mejores características basadas en pruebas univariadas).\n",
    "            k_best = SelectKBest(score_func=f_classif, k=params)  # Inicializa el selector de las mejores características.\n",
    "            k_best.fit(features, target)  # Ajusta el selector a las características y el objetivo.\n",
    "            selected_features = features.columns[k_best.get_support()]  # Obtiene las características seleccionadas.\n",
    "            result[selector] = selected_features.tolist()  # Almacena las características seleccionadas en el resultado.\n",
    "\n",
    "        elif selector == \"FromModel\":  # Si el método de selección es 'FromModel' (Selección de características basadas en un modelo externo).\n",
    "            model, threshold = params  # Obtiene el modelo y el umbral de los parámetros.\n",
    "            if isinstance(threshold, int):  # Comprueba si el umbral es un número entero.\n",
    "                max_features = threshold  # Si es un número entero, se establece como el número máximo de características.\n",
    "                threshold = -np.inf  # El umbral se establece en infinito negativo.\n",
    "            else:\n",
    "                max_features = None  # Si no es un número entero, el número máximo de características no se limita.\n",
    "            selector_model = SelectFromModel(model, threshold=threshold, max_features=max_features)  # Inicializa el selector basado en el modelo.\n",
    "            selector_model.fit(features, target)  # Ajusta el selector a las características y el objetivo.\n",
    "            selected_features = features.columns[selector_model.get_support()]  # Obtiene las características seleccionadas.\n",
    "            result[selector] = selected_features.tolist()  # Almacena las características seleccionadas en el resultado.\n",
    "\n",
    "        elif selector == \"RFE\":  # Si el método de selección es 'RFE' (Eliminación recursiva de características).\n",
    "            model, n_features, step = params  # Obtiene el modelo, el número de características y el paso de los parámetros.\n",
    "            rfe = RFE(estimator=model, n_features_to_select=n_features, step=step)  # Inicializa el selector de RFE.\n",
    "            rfe.fit(features, target)  # Ajusta el selector a las características y el objetivo.\n",
    "            selected_features = features.columns[rfe.support_]  # Obtiene las características seleccionadas.\n",
    "            result[selector] = selected_features.tolist()  # Almacena las características seleccionadas en el resultado.\n",
    "\n",
    "        elif selector == \"SFS\":  # Si el método de selección es 'SFS' (Selección secuencial hacia adelante).\n",
    "            model, n_features = params  # Obtiene el modelo y el número de características de los parámetros.\n",
    "            sfs = SequentialFeatureSelector(model, k_features=n_features, forward=True, floating=False, scoring='accuracy', cv=StratifiedKFold(5))  # Inicializa el selector SFS.\n",
    "            sfs.fit(features, target)  # Ajusta el selector a las características y el objetivo.\n",
    "            selected_features = features.columns[list(sfs.k_feature_idx_)]  # Obtiene las características seleccionadas.\n",
    "            result[selector] = selected_features.tolist()  # Almacena las características seleccionadas en el resultado.\n",
    "\n",
    "    # Realizar hard voting\n",
    "    \n",
    "    all_features = [result[key] for key in result]  # Combinar todas las listas seleccionadas\n",
    "    all_features.extend(hard_voting)\n",
    "    if all_features:\n",
    "        voting_counts = Counter([feature for sublist in all_features for feature in sublist if feature in features.columns])\n",
    "        sorted_voting = sorted(voting_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        hard_voting_result = [feature[0] for feature in sorted_voting[:len(hard_voting)]]\n",
    "        result['hard_voting'] = hard_voting_result\n",
    "    elif len(result) == 1:\n",
    "        result['hard_voting'] = result[next(iter(result))]\n",
    "\n",
    "    return result\n",
    "\n",
    "    return result  # Devuelve el resultado que contiene las características seleccionadas por cada método de selección y el resultado del hard voting si se especifica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds = pd.read_csv(\"diamonds_preparado.csv\", sep = \"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53940 entries, 0 to 53939\n",
      "Data columns (total 23 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   carat         53940 non-null  float64\n",
      " 1   cut           53940 non-null  object \n",
      " 2   depth         53940 non-null  float64\n",
      " 3   table         53940 non-null  float64\n",
      " 4   price         53940 non-null  int64  \n",
      " 5   x             53940 non-null  float64\n",
      " 6   y             53940 non-null  float64\n",
      " 7   z             53940 non-null  float64\n",
      " 8   color_D       53940 non-null  int64  \n",
      " 9   color_E       53940 non-null  int64  \n",
      " 10  color_F       53940 non-null  int64  \n",
      " 11  color_G       53940 non-null  int64  \n",
      " 12  color_H       53940 non-null  int64  \n",
      " 13  color_I       53940 non-null  int64  \n",
      " 14  color_J       53940 non-null  int64  \n",
      " 15  clarity_IF    53940 non-null  int64  \n",
      " 16  clarity_VVS1  53940 non-null  int64  \n",
      " 17  clarity_VVS2  53940 non-null  int64  \n",
      " 18  clarity_VS1   53940 non-null  int64  \n",
      " 19  clarity_VS2   53940 non-null  int64  \n",
      " 20  clarity_SI1   53940 non-null  int64  \n",
      " 21  clarity_SI2   53940 non-null  int64  \n",
      " 22  clarity_I1    53940 non-null  int64  \n",
      "dtypes: float64(6), int64(16), object(1)\n",
      "memory usage: 9.5+ MB\n"
     ]
    }
   ],
   "source": [
    "diamonds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un diccionario de mapeo de etiquetas a valores numéricos\n",
    "mapping = {'Ideal': 5, 'Premium': 4, 'Very Good': 3, 'Good': 2, 'Fair': 1}\n",
    "\n",
    "# Aplicar el mapeo al DataFrame\n",
    "diamonds['cut'] = diamonds['cut'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>color_D</th>\n",
       "      <th>color_E</th>\n",
       "      <th>...</th>\n",
       "      <th>color_I</th>\n",
       "      <th>color_J</th>\n",
       "      <th>clarity_IF</th>\n",
       "      <th>clarity_VVS1</th>\n",
       "      <th>clarity_VVS2</th>\n",
       "      <th>clarity_VS1</th>\n",
       "      <th>clarity_VS2</th>\n",
       "      <th>clarity_SI1</th>\n",
       "      <th>clarity_SI2</th>\n",
       "      <th>clarity_I1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>5</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>4</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>2</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>4</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53935</th>\n",
       "      <td>0.72</td>\n",
       "      <td>5</td>\n",
       "      <td>60.8</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.76</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53936</th>\n",
       "      <td>0.72</td>\n",
       "      <td>2</td>\n",
       "      <td>63.1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.69</td>\n",
       "      <td>5.75</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53937</th>\n",
       "      <td>0.70</td>\n",
       "      <td>3</td>\n",
       "      <td>62.8</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.66</td>\n",
       "      <td>5.68</td>\n",
       "      <td>3.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53938</th>\n",
       "      <td>0.86</td>\n",
       "      <td>4</td>\n",
       "      <td>61.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>6.15</td>\n",
       "      <td>6.12</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53939</th>\n",
       "      <td>0.75</td>\n",
       "      <td>5</td>\n",
       "      <td>62.2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.83</td>\n",
       "      <td>5.87</td>\n",
       "      <td>3.64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53940 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat  cut  depth  table  price     x     y     z  color_D  color_E  \\\n",
       "0       0.23    5   61.5   55.0    326  3.95  3.98  2.43        0        1   \n",
       "1       0.21    4   59.8   61.0    326  3.89  3.84  2.31        0        1   \n",
       "2       0.23    2   56.9   65.0    327  4.05  4.07  2.31        0        1   \n",
       "3       0.29    4   62.4   58.0    334  4.20  4.23  2.63        0        0   \n",
       "4       0.31    2   63.3   58.0    335  4.34  4.35  2.75        0        0   \n",
       "...      ...  ...    ...    ...    ...   ...   ...   ...      ...      ...   \n",
       "53935   0.72    5   60.8   57.0   2757  5.75  5.76  3.50        1        0   \n",
       "53936   0.72    2   63.1   55.0   2757  5.69  5.75  3.61        1        0   \n",
       "53937   0.70    3   62.8   60.0   2757  5.66  5.68  3.56        1        0   \n",
       "53938   0.86    4   61.0   58.0   2757  6.15  6.12  3.74        0        0   \n",
       "53939   0.75    5   62.2   55.0   2757  5.83  5.87  3.64        1        0   \n",
       "\n",
       "       ...  color_I  color_J  clarity_IF  clarity_VVS1  clarity_VVS2  \\\n",
       "0      ...        0        0           0             0             0   \n",
       "1      ...        0        0           0             0             0   \n",
       "2      ...        0        0           0             0             0   \n",
       "3      ...        1        0           0             0             0   \n",
       "4      ...        0        1           0             0             0   \n",
       "...    ...      ...      ...         ...           ...           ...   \n",
       "53935  ...        0        0           0             0             0   \n",
       "53936  ...        0        0           0             0             0   \n",
       "53937  ...        0        0           0             0             0   \n",
       "53938  ...        0        0           0             0             0   \n",
       "53939  ...        0        0           0             0             0   \n",
       "\n",
       "       clarity_VS1  clarity_VS2  clarity_SI1  clarity_SI2  clarity_I1  \n",
       "0                0            0            0            1           0  \n",
       "1                0            0            1            0           0  \n",
       "2                1            0            0            0           0  \n",
       "3                0            1            0            0           0  \n",
       "4                0            0            0            1           0  \n",
       "...            ...          ...          ...          ...         ...  \n",
       "53935            0            0            1            0           0  \n",
       "53936            0            0            1            0           0  \n",
       "53937            0            0            1            0           0  \n",
       "53938            0            0            0            1           0  \n",
       "53939            0            0            0            1           0  \n",
       "\n",
       "[53940 rows x 23 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TransformerMixin.fit_transform() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m----> 2\u001b[0m diamonds \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mStandardScaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiamonds\u001b[49m\u001b[43m)\u001b[49m, columns\u001b[38;5;241m=\u001b[39mdiamonds\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "\u001b[0;31mTypeError\u001b[0m: TransformerMixin.fit_transform() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "diamonds = pd.DataFrame(StandardScaler.fit_transform(diamonds), columns=diamonds.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_diamonds, test_set_diamonds = train_test_split(diamonds, test_size = 0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\n",
      "STOPPING EARLY DUE TO KEYBOARD INTERRUPT..."
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Ejemplo de uso\u001b[39;00m\n\u001b[1;32m      2\u001b[0m selectores \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKBest\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFromModel\u001b[39m\u001b[38;5;124m\"\u001b[39m: [RandomForestClassifier(), \u001b[38;5;241m5\u001b[39m],\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRFE\u001b[39m\u001b[38;5;124m\"\u001b[39m: [LogisticRegression(), \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSFS\u001b[39m\u001b[38;5;124m\"\u001b[39m: [RandomForestClassifier(), \u001b[38;5;241m5\u001b[39m] \n\u001b[1;32m      7\u001b[0m }\n\u001b[0;32m----> 8\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43msuper_selector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set_diamonds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcut\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselectores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselectores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhard_voting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdepth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclarity_VVS1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m result\n",
      "Cell \u001b[0;32mIn[2], line 66\u001b[0m, in \u001b[0;36msuper_selector\u001b[0;34m(dataset, target_col, selectores, hard_voting)\u001b[0m\n\u001b[1;32m     64\u001b[0m         sfs \u001b[38;5;241m=\u001b[39m SequentialFeatureSelector(model, k_features\u001b[38;5;241m=\u001b[39mn_features, forward\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, floating\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39mStratifiedKFold(\u001b[38;5;241m5\u001b[39m))  \u001b[38;5;66;03m# Inicializa el selector SFS.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m         sfs\u001b[38;5;241m.\u001b[39mfit(features, target)  \u001b[38;5;66;03m# Ajusta el selector a las características y el objetivo.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m         selected_features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;28mlist\u001b[39m(sfs\u001b[38;5;241m.\u001b[39mk_feature_idx_)]  \u001b[38;5;66;03m# Obtiene las características seleccionadas.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m         result[selector] \u001b[38;5;241m=\u001b[39m selected_features\u001b[38;5;241m.\u001b[39mtolist()  \u001b[38;5;66;03m# Almacena las características seleccionadas en el resultado.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Realizar hard voting\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso\n",
    "selectores = {\n",
    "    \"KBest\": 5,\n",
    "    \"FromModel\": [RandomForestClassifier(), 5],\n",
    "    \"RFE\": [LogisticRegression(), 5, 1],\n",
    "    \"SFS\": [RandomForestClassifier(), 5] \n",
    "}\n",
    "result = super_selector(train_set_diamonds, target_col=\"cut\", selectores=selectores, hard_voting=[\"depth\",\"price\",\"table\",\"y\",\"clarity_VVS1\"])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si hard_voting era lista vacia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KBest': ['pclass', 'fare', 'who', 'alone', 'embarked_C'],\n",
       " 'FromModel': ['pclass', 'age', 'sibsp', 'fare', 'who'],\n",
       " 'RFE': ['pclass', 'sibsp', 'who', 'alone', 'embarked_C'],\n",
       " 'SFS': ['pclass', 'sibsp', 'who', 'alone', 'embarked_Q']}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo de uso\n",
    "selectores = {\n",
    "    \"KBest\": 5,\n",
    "    \"FromModel\": [RandomForestClassifier(), 5],\n",
    "    \"RFE\": [LogisticRegression(), 5, 1],\n",
    "    \"SFS\": [RandomForestClassifier(), 5] \n",
    "}\n",
    "result = super_selector(train_set_diamonds, target_col=\"survived\", selectores=selectores, hard_voting=[])\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
